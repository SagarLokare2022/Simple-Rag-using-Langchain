{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308d3a2f",
   "metadata": {},
   "source": [
    "üìåYouTube Transcript RAG System Using Whisper + LangChain\n",
    "  Build an end-to-end Retrieval Augmented Generation (RAG) pipeline \n",
    "for YouTube videos using Whisper, FAISS, and LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4837b3",
   "metadata": {},
   "source": [
    "üìñ Project Overview\n",
    "\n",
    "This project demonstrates how to convert any public YouTube video into a searchable knowledge system using a Retrieval Augmented Generation (RAG) pipeline.\n",
    "\n",
    "You provide a YouTube URL, and the system:\n",
    "\n",
    "Downloads the video‚Äôs audio\n",
    "\n",
    "Transcribes it using OpenAI Whisper\n",
    "\n",
    "Chunks the text using LangChain\n",
    "\n",
    "Creates embeddings using OpenAI\n",
    "\n",
    "Stores them in a FAISS Vector DB\n",
    "\n",
    "Retrieves relevant chunks based on a question\n",
    "\n",
    "Feeds them into an LLM for final answer generation\n",
    "\n",
    "This notebook is an end-to-end demonstration of a real RAG chatbot applied to YouTube content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d0a422",
   "metadata": {},
   "source": [
    "üß± Architecture\n",
    "\n",
    "YouTube URL\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "Download Audio with pytubefix\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "OpenAI Whisper ‚Üí Transcript Text\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "Chunking (RecursiveCharacterTextSplitter)\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "OpenAI Embeddings ‚Üí Vector DB (FAISS)\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "Retriever\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "Composable LangChain Pipeline\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "LLM Answer (ChatOpenAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70103934",
   "metadata": {},
   "source": [
    "üöÄ 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ea6c9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pytubefix import YouTube\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e69da",
   "metadata": {},
   "source": [
    "üéß 2. Download YouTube Audio\n",
    "\n",
    "This function extracts audio-only from a YouTube video and saves it as audio.mp4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58265d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_youtube_audio(url, filename=\"audio.mp4\"):\n",
    "    save_path = r\"c:\\Users\\HP\\Desktop\\sagar_handson\" \n",
    "    yt = YouTube(url)\n",
    "    stream = yt.streams.filter(only_audio=True).first()\n",
    "    # This will save the audio in the same folder as this script\n",
    "    file_path = stream.download(output_path=save_path, filename=filename)\n",
    "    print(\"Saved at:\", file_path)\n",
    "    print(\"Exists?\", os.path.exists(file_path))\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "994b3395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: c:\\Users\\HP\\Desktop\\sagar_handson\\audio.mp4\n",
      "Exists? True\n"
     ]
    }
   ],
   "source": [
    "audio_path = download_youtube_audio(\"https://www.youtube.com/watch?v=HFfXvfFe9F8&t=16s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ff633",
   "metadata": {},
   "source": [
    "ü§ñ 3. Transcribe Audio Using Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8ba24fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello all my name is Krushnayak and welcome to my YouTube channel. So guys yet another amazing video here we are going to create an end-to-end project using Google Gemini Pro and project name is related to YouTube videos transcriber. Now this is an amazing project our main aim will be that we will try to just give the video YouTube link YouTube video link and then it should be able to automatically extract all the text all the transcript text from that specific videos. Now before I go ahead and start implementing this I would like to give some important credits to Dipendra Verma so you can see that his post was there and here you can see like what all things he has specifically implemented and by seeing the tutorials right where I've created a lot of Gemini Google Gemini projects he has specifically used this and he has actually created this so I asked for the link so that you know I could have made a video for you all but again this entire project credit goes to Dipendra Verma and but I will try to implement it completely from scratch how you can actually do the setup each and everything as we go ahead okay so again Dipendra Verma thank you very much and again his LinkedIn will be provided in the description on this particular video you can go ahead and you know probably contact him ask him any questions if you have okay so let me quickly go ahead and start this specific project so here is this particular project so first of all as usual what we are going to do is that we're going to go to the terminal and create our new environment okay so in order to create our new environment I will go ahead and write Honda so I don't want to do it in PowerShell so let me just go back to command prompt and this is the first step that you specifically require and we have done this conduct create be V and V and I'm going to specifically use Python 3.1 0 right and I'll also give dash Y so that it does not ask me any permissions with respect to the installation so till the environment is going and getting created what I'm actually going to do is that I'll go ahead and create some of the files like dot ENV I also require requirements dot txt so and one more file we will try to create one is app dot py okay and we'll start writing our specific code with respect to this okay now what are libraries we specifically require and all as you know that we are going to use this Google Gemini Pro over here right so let me do one thing first of all let me go ahead and create an environment variable so for that I will copy this API key from makers would dot google.com and I will go ahead and paste it over here right you can also do it completely it is for free Google provides you this for free for some number of requests right so here I will write Google underscore API Google underscore API underscore key is equal to this specific environment variable okay I'm going to set this up as an environment variable I will close this I will go ahead and activate my VM environment whatever libraries I really need to install it will be installed in in this specific environment itself right so the VM environment is created and we have activated it now the next thing that we have specifically going to do is that we will go ahead and use some of the libraries that we are going to use in this project one is YouTube transcript underscore API why this YouTube underscore transcript underscore API is used let me just go ahead and show you so YouTube underscore transcript underscore API so if you probably go ahead and see this is a Python API which allows you to get the transcript of subtitles from a given YouTube video it also works for automatically generated subtitles supports translation of subtitles and does not require a headless browser like selenium based solutions to okay so just by using this specific libraries we can probably you know extract all the transcript details that we have okay so let's do one thing let's go ahead and install this I have already installed it anyhow right no I have not installed it so I will go ahead and install it so YouTube transcript API will be required streamlet I'm going to use as a front-end Google generative AI Python dash dot ENV partly okay so these are libraries we are going to install so let's quickly go ahead and write pip install minus our requirement dot txt okay let me create the screen pip install minus our requirement dot txt so quickly let's see so it has not installed let me see okay it is not saved this file needs to be saved anyhow now let's go ahead and do the installation perfect so once it gets installed we will start our coding in our app dot py5 okay and for coding also just understand that what all things we specifically require over here right so till this installation basically takes place till then I will go ahead and write the code import streamlet as ST okay I'm going to use streamlet along with this I'm also going to import from dot ENV I'm going to import load underscore dot ENV specifically we require this for loading our API keys sorry environment variables and after this I will load underscore dot ENV okay so right now it is not giving us any suggestion because still the requirements the libraries are getting installed right so after some time you will be able to see that we will also be able to see each and every suggestions from this okay so I've loaded this in this in short will load all the environment variables load all the environment variables okay so this is also done then import Google dot generative AI as journey I done so this is also important I'm going to specifically use this now you can see that this entire thing is loaded let me just go ahead and save it okay perfect this looks good from dot ENV load underscore dot ENV this is there this is there let me just have a look what is the error okay so from import Google dot generative AI as a journey I have already done this I have also imported streamlet dot ENV now from I'll also create a separate utility file let me do that in the later stage now first thing after doing this is that I will go ahead and configure so I will write gen AI dot configure inside this I will go ahead and write API underscore key is equal to OS dot get ENV so I've not imported OS also let me just go ahead and import it import OS okay OS dot get ENV and whatever is my environment variable I'm going to basically go to write that specific thing over here so I'll go to my ENV file call my Google API key and that is nothing but my API key over here when you close till there okay so once this is done we have configured the gen AI now I'm going to create a function which is called as you know the fetch transcript something like this right so here I'm going to basically create a fresh transcript this will be responsible in fetching the transcript details you know from let's okay let me just remove this right now let me do one thing let me go ahead and write this generate underscore Gemini underscore content okay so I'll first of all create this function okay and inside this what all things I really need to give so this generate Gemini content what it's going to do it is first of all going to take my transcript okay because at the end of the day I need to create a summary out of it so transcript will be the first thing this will not be this will be a text in short whatever text we are able to get from the YouTube video the second thing is that I can actually create a subject field like what this transcript is all about you know whether it is for data science or machine learning or physics so category wise we can specifically use it if you don't want to use this it's okay you can directly probably take this transcript and you can probably tell hey just provide me a summary right so let me do one thing let me remove this subject also I don't require this subject right now so what what I will do over here once I get the transcript you know I will go ahead and create a prompt or if you want I can also give the prompt over here itself right so let me just go ahead and give the prompt and let me create the prompt over here all right let's say here I will say you are a YT or YouTube video summarizer summarizer you will you will be taking the transcript text transcript text and summarizing the entire video transcripts text okay let me use triple quotes okay summarizing the entire video and providing the important summary summary in point wise in points within within 200 or 250 words okay so I've given this simple prompt as soon as this prompt is given over here now what Google Gemini is basically going to do over here right we are going to probably just use this model dot gen AI dot gen AI dot generate sorry generate content right gen AI dot oh just a second first of all gen AI dot generative generative AI oh sorry generative model I'm going to use and call the model itself right so it will be nothing but Gemini Pro right once I probably get this Gemini Pro now what I'm actually going to do is that I will take this model which will responsible in working with text and then I will specifically use this particular model and create our response so here I will go ahead and write model dot generate generate underscore content right and here I'm going to specifically use this prompt that I have along with this prompt I'm also going to give the transcript text I will combine this and probably give this transcript text now here you can probably see right I am giving this combination right prompt plus transcript text okay you are a YouTube video summarizer you will be taking that taking the transcript text and summarizing the entire video and providing the important summary in points within 250 words the transcript text will be appended here okay something like this right and over here whatever transcript text we are specifically going to create you can include it over here itself right so here what we will you can also do is that you can create a prompt variable itself but right now let's go over here and keep it like this and let's see whether this is going to work or not okay but anyhow I'm going to give this entire prompt text itself okay so and I'm since I'm appending it over here that basically means it gets appended over here itself right so this I'm going to get the response and let me go ahead and write response dot response dot text okay so I'm going to return the response dot text now understand about this right this is when we are interacting with the Google Gemini Pro model right but still our main method that we have right the most important method I'll say is to take out the transcript from the video right over here we are trying to do the summarization of this transcript right that we are getting from the YouTube video so for that what all libraries we will be using and what all function I will be creating so here I will go ahead and write from YouTube underscore transcript transcript underscore API I'm going to import so I'm going to you import this library again from the transcript that I have actually downloaded now this YouTube transcript API will be responsible in getting from the video URL from the video URL it will try to get the ID of the video and then it will try to retrieve the entire transcript and remember all the videos needs to be public right if it is private it will not work so what we are going to do after this is that we will create a function and this function is nothing but let me go ahead and create this function this function is definition extract transcript underscore details okay so here we are going to give my YouTube video URL okay so this is the input that I am going to give now from this view to video URL let me go ahead and write a try catch block so that we handle the exception also so try pass and the next thing in that I will be writing is nothing but except and let me raise one exception exception as e and I can probably raise e okay so this is the exception that I'm going to probably raise now let's say I give the video URL first of all I need to get the video ID now in order to get the video ID if you probably see in this specific videos right like let's say this is my most popular video in my channel this text that you see over here is the video ID so based on this video ID this YouTube API right whatever API we are specifically using it will be able to extract the entire transcript so I have to split from this URL this particular ID so how do we do that it is very simple a simple Python code I will go ahead and write you to video URL dot split now the main split should be happening with respect to this equal to right so I will go ahead and write equal to over here right now once we write equal to it is going to divide this into two terms zero index and first index so first index will basically have the ID itself so I will take the first index over here okay now this is done the next thing that I'm going to basically write is my transcript transcript text okay now this transcript text will I will call this YouTube transcript API and then use dot get transcript okay and here I'm going to basically give the video ID okay so this is the function that is sorry it should be get underscore transcript okay this is the function that we specifically use in from this particular YouTube transcript API now once we get the transcript text what we can in short like this this transcript right now is in form of a list right it will be having a lot of lists over there right one by one so what we will do one by one we will go ahead and append this together so that we form this as a paragraph so here you can see I have let me initialize this over here like this and let me do one thing okay so I'm saying from I in transcript text which is coming in the form of list list over here I will go ahead and append in this particular variable in the form of a paragraph okay I'm going to take all the text and append it over here and once we do this after doing this we can return this transcript okay so here we are going to return this transcript after this entire step is done now these are the two main functionalities this is probably exploring or I will write getting the transcript getting the transcript data from YT videos okay YT videos and then here getting the summary getting the summary based on prompt okay based on prompt from Google Gemini I hope everybody is very much clear with this right so these are the two main functionalities now the remaining part that is there is very simple you just need to create a streamlet app and probably define all these things okay so what I am actually going to do I will go ahead and create some streamlet app over here so I will go ahead and write st dot title okay so this will be my YouTube transcript or detail notes converter I will create a text input box okay and this text input box will actually help me to get a YouTube link once I probably get the YouTube link so let's say if I get the YouTube link what we can actually do is that we can also display the thumbnail image right so what we are going to do over here is that we will go ahead and split again with respect to the video ID okay so video ID I will just split it and take the first one I will get the same video ID and then we can use st dot image to display the image itself right and this image URL is the default image URL that whenever you try to upload an image in YouTube in the form of thumbnail this is where it is stored and the reference over here is with respect to the video ID okay so this is how the entire URL is basically constructed so as soon as we provide the link over there okay and you can probably see that the image of that particular thumbnail of that video will be displayed in the bottom part now I will also create a button okay and this button will be like get the detailed description and all something like this okay so here we can go ahead and write one more function let's see so this is done so I'm saying if st dot button if you're getting clicking this get detail notes then first thing what we really need to crop is this nothing but extract transcript right so this function we will specifically call and here I'm going to give my YouTube link okay once we call this we are just going to get our entire transcript text right so here I'm going to transcript here I'm going to specifically get my transcript text okay now if this transcript text if I get this transcript text then the next function that I have to call is nothing but generate Gemini content okay so here you'll be able to see generate Gemini content this will be my summary and here I will give two important information one what all information I will give one is the let me see one is the transcript text and next is a prompt so here I'm going to probably give my transcript text and the second one is nothing but by prompt so the prompt variable is created over here and it is created over here everything looks the transcript text will be appended over here please provide the summary of the text given here okay something like this I'm writing done generate Gemini content I'll get the summary once I probably get the summary all I have to do is that use markdown and write this code over here markdown and write and I will be getting the summary itself okay so this will basically be my summary so once this is done let's see whether everything will work fine or not I don't know let's see I'm not run it yet okay so let me just go ahead and write it over here now to run it I will go ahead and write streamlet run app dot py again my main aim is to simplify this if you want to see more different kind of implementation away you can also refer the person LinkedIn that are actually given over there okay so here let me go ahead and write my best video let's see krishnaic AI ML dl okay so this video we will try to see here you go I will copy the link address I'll paste it over here let's see I think enter okay still we are not getting it over here the the image thumbnail we are not able to get it so let's let's print this what video ID we are able to get let's see what is the video ID I think we should get the video ID right so print video underscore ID here also I can print it and one more I'll just copy this I'll print it over here also so if YouTube link I will always rerun it let's press enter let's reload it once again we'll take this copy link address press enter okay I'm getting this error let's see video ID is coming as key to P let's see let's see let's see what is this okay I have to give just like this let's see I will copy this now let's reload it and press enter so this is the thumbnail that we are specifically getting it from this video and now I will click on get detailed notes everything is running fine let's see I think it's working fine since it is already taking so much time so I think I should be able to get the response it's running it's running I think we have got it artificial intelligence intelligence there's this this machine learning this this this this everything right so the entire explanation of this particular video is given over here let me just take my recent video okay and let's try once more so here is the image it is also being able to extract the entire thumbnail image which is good right so it's running I think it should work fine now okay here you go generative as a field is this this this cloud platform like AWS bedrock now you can modify this prompt right your YouTube video summarizer will be taking the transcript text and all and all you can you can write it with your own way like how you want okay I will just show you like how that person has actually written it right let's see okay he had written something like this I will I will show you he had written it something like this okay title vital everything is written like this okay title this this this let's see how we are able to get this response in this way or not always rerun if I go ahead and click on get detailed notes so he's written this big prompt engineering right different prompt explain fundamental concepts and data science out like basic statistical you note should aim to offer a clear understanding of all these things please provide the YouTube video transcript I will generate the detailed notes on data science and statistics accordingly again this is like you play it right so everything is written over here and you can probably check it out right but at the end of the day I will give you a simple one and at the end of the you can try as many as you like okay so I hope altogether you love this video you like this video I hope you are able to understand things as we go ahead more interesting videos are going to come I'm also going to explore more videos on llama index they are also I'm also exploring one amazing library which will actually help you to learn run the local LLM models right now in Windows it has not come in it is there in Linux and Mac I have to probably record that video in Mac itself I already have a MacBook so let's see I'll do that but if you like this particular video please do share with all your friends and this was it from my side I'll see you in the next video thank you take care bye bye\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()   # assumes OPENAI_API_KEY is set in your environment\n",
    "\n",
    "audio_path = \"audio.mp4\"   # the file pytubefix created\n",
    "\n",
    "with open(audio_path, \"rb\") as audio_file:\n",
    "    transcript = client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=audio_file,\n",
    "        # language=\"en\",  # optional: force English if needed\n",
    "    )\n",
    "\n",
    "print(transcript.text) #test if the extract works as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf10065b",
   "metadata": {},
   "source": [
    "‚úÇÔ∏è 4. Chunk the Transcript for RAG\n",
    "\n",
    "Using an optimal chunk size for YouTube content:\n",
    "\n",
    "chunk_size = 1000\n",
    "\n",
    "chunk_overlap = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d4256175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000,chunk_overlap = 250)\n",
    "chunks = splitter.create_documents([transcript.text]) # needs to be in a list for splitting\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17042acc",
   "metadata": {},
   "source": [
    "üîé 5. Create Embeddings and Build Vector DB (FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "97bf8240",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c0782da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002138666B110>, search_kwargs={'k': 4})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b369d4d",
   "metadata": {},
   "source": [
    "üìÑ 6. Prompt Template for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e279ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "      You are a helpful assistant.\n",
    "      Answer ONLY from the provided transcript context.\n",
    "      If the context is insufficient, just say you don't know.\n",
    "\n",
    "      {context}\n",
    "      Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables = ['context', 'question']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eedf95",
   "metadata": {},
   "source": [
    "üîó 7. Build the Parallel RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a5af65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(retrieved_docs):\n",
    "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "  return context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "631f47b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    'context': retriever | RunnableLambda(format_docs),\n",
    "    'question': RunnablePassthrough()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aba1ef",
   "metadata": {},
   "source": [
    "üß† 8. Build the Final RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d17521d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()\n",
    "llm = ChatOpenAI(model=\"gpt-5-mini\")\n",
    "final_chain = parallel_chain | prompt | llm | parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc46b62",
   "metadata": {},
   "source": [
    "üß™ 9. Test RAG ‚Äî Example Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3cad2170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The speaker demonstrates a YouTube video-summarizer workflow that takes transcript text and generates concise, point-wise summaries or detailed notes (e.g., on data science and statistics) using configurable prompts.  \n",
      "- They show how to create and modify the prompt (example: instructing the summarizer to produce a 200‚Äì250 word summary) and how to remove unnecessary fields like subject.  \n",
      "- The tool extracts additional assets such as the video thumbnail and appears to run reliably across examples.  \n",
      "- The presenter mentions exploring related tools and libraries (LlamaIndex and local LLMs on Linux/Mac) and references generative AI topics like machine learning and cloud platforms (e.g., AWS Bedrock).  \n",
      "- They encourage viewers to try multiple prompts, share the video, and announce more related content coming soon.\n"
     ]
    }
   ],
   "source": [
    "result = final_chain.invoke(\"summarize the video for me in 5 lines\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c752c86",
   "metadata": {},
   "source": [
    "üèÅ Final Results\n",
    "\n",
    "‚úî End-to-end RAG pipeline\n",
    "‚úî YouTube ‚Üí Audio ‚Üí Whisper Transcript ‚Üí Chunking ‚Üí Embeddings ‚Üí FAISS ‚Üí Retriever ‚Üí LLM\n",
    "‚úî Accurate responses with rich context\n",
    "‚úî Clean modular LangChain architecture\n",
    "‚úî Ready for Streamlit UI (future improvement)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
